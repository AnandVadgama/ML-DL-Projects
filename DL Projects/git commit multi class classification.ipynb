{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM8yQH8RAXa2kDI47v6pFLb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"nB-NpOb3Zclt","executionInfo":{"status":"ok","timestamp":1752385261541,"user_tz":-330,"elapsed":34145,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from sentence_transformers import SentenceTransformer\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["texts = [\n","    # Learning (0)\n","    \"reading about transformer architecture implementation\",\n","    \"experimenting with positional encodings\",\n","    \"studying multi-head attention concept\",\n","    \"tried understanding residual connections in deep models\",\n","    \"ran tutorial on encoder-decoder models\",\n","    \"exploring self-supervised learning pipeline\",\n","    \"tested code from vision transformer repo\",\n","    \"learning how attention works with queries and keys\",\n","    \"watched lecture on language modeling techniques\",\n","    \"reviewed papers on sentence embeddings\",\n","    \"built prototype to learn attention masks\",\n","    \"debugged BERT tokenizer to understand input IDs\",\n","    \"attempted to fine-tune pre-trained model on dummy data\",\n","    \"evaluating knowledge distillation in transformers\",\n","    \"understanding causal attention flow in GPT\",\n","    \"testing weight initialization methods on dummy net\",\n","    \"running slow training loop just to observe gradients\",\n","    \"writing notes on LLaMA model architecture\",\n","    \"trying out LoRA with HuggingFace Trainer\",\n","    \"visualizing embeddings with t-SNE\",\n","\n","    # Building (1)\n","    \"added attention mask support to training loop\",\n","    \"implemented feedforward block with layer norm\",\n","    \"built custom positional embedding layer\",\n","    \"added config support for hyperparameters\",\n","    \"implemented token classification head\",\n","    \"created a training script for BERT fine-tuning\",\n","    \"added support for dropout in encoder block\",\n","    \"integrated HuggingFace tokenizer with custom dataset\",\n","    \"created CLI to run inference on test data\",\n","    \"wrote script to convert raw data to tokenized format\",\n","    \"added multi-label loss support in training loop\",\n","    \"built transformer from scratch in PyTorch\",\n","    \"initialized weights from pre-trained model\",\n","    \"added callback for early stopping during training\",\n","    \"implemented batch inference pipeline\",\n","    \"created config file parser for experiments\",\n","    \"added tensorboard logging utilities\",\n","    \"built model saving and loading logic\",\n","    \"wrapped model in FastAPI for deployment\",\n","    \"generated predictions on test dataset\",\n","\n","    # Fixing (2)\n","    \"fixed bug in attention score normalization\",\n","    \"corrected learning rate decay logic\",\n","    \"resolved tensor shape mismatch in decoder\",\n","    \"patched device mismatch error in training loop\",\n","    \"removed duplicated loss computation\",\n","    \"fixed NaN issue in softmax calculation\",\n","    \"resolved indexing error in token embeddings\",\n","    \"fixed data loader drop_last parameter issue\",\n","    \"replaced deprecated PyTorch functions\",\n","    \"fixed memory leak in model checkpoint logic\",\n","    \"corrected mask broadcast issue\",\n","    \"fixed model.eval() missing in validation loop\",\n","    \"patched error in early stopping condition\",\n","    \"fixed float32 vs float16 conflict on CUDA\",\n","    \"fixed crash when input length exceeds max_tokens\",\n","    \"debugged gradient clipping logic\",\n","    \"fixed improper tokenizer padding\",\n","    \"re-initialized optimizer after resuming checkpoint\",\n","    \"fixed bug in argmax index logging\",\n","    \"resolved seed reproducibility inconsistency\",\n","\n","    # Refactoring (3)\n","    \"refactored model class to use nn.ModuleList\",\n","    \"simplified training loop using trainer class\",\n","    \"renamed variables for clarity\",\n","    \"moved config parsing to separate module\",\n","    \"removed unused imports and functions\",\n","    \"modularized data preprocessing code\",\n","    \"cleaned up optimizer scheduler logic\",\n","    \"restructured main.py into CLI + core logic\",\n","    \"refactored forward pass to reduce redundancy\",\n","    \"simplified activation functions for readability\",\n","    \"migrated training args into yaml config\",\n","    \"moved data augmentation out of main script\",\n","    \"refactored logging to support wandb and tensorboard\",\n","    \"organized utils into proper modules\",\n","    \"merged redundant functions into single pipeline\",\n","    \"removed legacy code blocks\",\n","    \"updated docstrings and inline comments\",\n","    \"standardized variable naming conventions\",\n","    \"grouped model layers into blocks\",\n","    \"rewrote dataset class for clarity and performance\"\n","]\n","\n","labels = [0]*20 + [1]*20 + [2]*20 + [3]*20\n"],"metadata":{"id":"OXELGff0aIY0","executionInfo":{"status":"ok","timestamp":1752385261542,"user_tz":-330,"elapsed":37,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["label_map = {\n","    0: \"learning\",\n","    1: \"building\",\n","    2: \"fixing\",\n","    3: \"refactoring\"\n","}"],"metadata":{"id":"0n4o3EON6skr","executionInfo":{"status":"ok","timestamp":1752385261542,"user_tz":-330,"elapsed":35,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSmr3b1a6tHh","executionInfo":{"status":"ok","timestamp":1752385267238,"user_tz":-330,"elapsed":5699,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}},"outputId":"3bf2f251-cf9c-4772-909d-730f7652a3a9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["embeddings = emb_model.encode(texts)\n","embeddings.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dG9pwf4w9J8R","executionInfo":{"status":"ok","timestamp":1752385267734,"user_tz":-330,"elapsed":495,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}},"outputId":"d1f2d81b-c4d1-4a87-cadb-396c33b5019e"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(80, 384)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["class Custom_dataset(Dataset):\n","\n","  def __init__(self, embeddings, labels):\n","    self.labels = labels\n","    self.embeddings = embeddings\n","\n","  def __len__(self):\n","    return len(self.embeddings)\n","\n","  def __getitem__(self, idx):\n","    return torch.tensor(self.embeddings[idx]), torch.tensor(self.labels[idx])"],"metadata":{"id":"BWao3tol8BXV","executionInfo":{"status":"ok","timestamp":1752385267829,"user_tz":-330,"elapsed":94,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42)"],"metadata":{"id":"QUc0_TMgQZSA","executionInfo":{"status":"ok","timestamp":1752385267927,"user_tz":-330,"elapsed":97,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train_dataset = Custom_dataset(X_train, y_train)\n","test_dataset = Custom_dataset(X_test, y_test)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=16)"],"metadata":{"id":"EJfEVriOQcv3","executionInfo":{"status":"ok","timestamp":1752385267929,"user_tz":-330,"elapsed":1,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class Commit_Classifier(nn.Module):\n","\n","  def __init__(self, input_dim: int):\n","    super().__init__()\n","    self.input_dim = input_dim\n","    self.cls = nn.Sequential(\n","        nn.Linear(input_dim, 128),\n","        nn.Dropout(0.1),\n","        nn.ReLU(),\n","        nn.LayerNorm(128),\n","        nn.Linear(128, 64),\n","        nn.Dropout(0.1),\n","        nn.ReLU(),\n","        nn.LayerNorm(64),\n","        nn.Linear(64, 4)\n","    )\n","\n","  def forward(self, x):\n","    return self.cls(x)"],"metadata":{"id":"z8G-Krzp-LJU","executionInfo":{"status":"ok","timestamp":1752385267931,"user_tz":-330,"elapsed":1,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["embeddings.shape[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uD4t5CclA9c2","executionInfo":{"status":"ok","timestamp":1752385268532,"user_tz":-330,"elapsed":594,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}},"outputId":"0070bfc3-0706-4830-8239-f5f67a7dcbcf"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["384"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["model = Commit_Classifier(embeddings.shape[1])"],"metadata":{"id":"sW_jv8EvAwQD","executionInfo":{"status":"ok","timestamp":1752385268533,"user_tz":-330,"elapsed":591,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["lr = 1e-3\n","epochs = 20\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"dNRhKqP1AnGz","executionInfo":{"status":"ok","timestamp":1752385268534,"user_tz":-330,"elapsed":10,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# training loop\n","for i in range(epochs):\n","  print(f\"Epoch {i+1}\")\n","  for x_train, y_train in train_dataloader:\n","    optimizer.zero_grad()\n","    y_pred = model(x_train)\n","    loss = loss_fn(y_pred, y_train)\n","    loss.backward()\n","    optimizer.step()\n","    print(f\"Loss: {loss.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gwBZHYkBMPl","executionInfo":{"status":"ok","timestamp":1752385269005,"user_tz":-330,"elapsed":471,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}},"outputId":"9a1568d6-d9df-4b12-ecb5-6ecca4b7ba6a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","Loss: 1.627692461013794\n","Loss: 1.4753458499908447\n","Loss: 1.4538193941116333\n","Loss: 1.448404312133789\n","Epoch 2\n","Loss: 0.8880918622016907\n","Loss: 0.9180330038070679\n","Loss: 1.0035710334777832\n","Loss: 0.8064764738082886\n","Epoch 3\n","Loss: 0.6431195139884949\n","Loss: 0.47221991419792175\n","Loss: 0.7190206050872803\n","Loss: 0.7078626155853271\n","Epoch 4\n","Loss: 0.4433968663215637\n","Loss: 0.5145807266235352\n","Loss: 0.4750795364379883\n","Loss: 0.5384621620178223\n","Epoch 5\n","Loss: 0.43820294737815857\n","Loss: 0.3518770635128021\n","Loss: 0.3367557227611542\n","Loss: 0.4132128357887268\n","Epoch 6\n","Loss: 0.32251667976379395\n","Loss: 0.30109018087387085\n","Loss: 0.32789817452430725\n","Loss: 0.2647404670715332\n","Epoch 7\n","Loss: 0.25290173292160034\n","Loss: 0.2946467995643616\n","Loss: 0.27042123675346375\n","Loss: 0.19401967525482178\n","Epoch 8\n","Loss: 0.24272114038467407\n","Loss: 0.1962645798921585\n","Loss: 0.1670837104320526\n","Loss: 0.17264580726623535\n","Epoch 9\n","Loss: 0.194443941116333\n","Loss: 0.19736549258232117\n","Loss: 0.12322194874286652\n","Loss: 0.15259955823421478\n","Epoch 10\n","Loss: 0.16033436357975006\n","Loss: 0.1425718367099762\n","Loss: 0.1340484917163849\n","Loss: 0.12823542952537537\n","Epoch 11\n","Loss: 0.12518653273582458\n","Loss: 0.0900598019361496\n","Loss: 0.11106199026107788\n","Loss: 0.09743106365203857\n","Epoch 12\n","Loss: 0.07778788357973099\n","Loss: 0.07558176666498184\n","Loss: 0.08997838199138641\n","Loss: 0.10472849756479263\n","Epoch 13\n","Loss: 0.0888567864894867\n","Loss: 0.061008572578430176\n","Loss: 0.09410978108644485\n","Loss: 0.07508533447980881\n","Epoch 14\n","Loss: 0.07588738948106766\n","Loss: 0.0679028108716011\n","Loss: 0.05658712610602379\n","Loss: 0.07787459343671799\n","Epoch 15\n","Loss: 0.052288707345724106\n","Loss: 0.06779087334871292\n","Loss: 0.058196064084768295\n","Loss: 0.06131141632795334\n","Epoch 16\n","Loss: 0.05760101228952408\n","Loss: 0.06354720145463943\n","Loss: 0.06313484162092209\n","Loss: 0.04699169471859932\n","Epoch 17\n","Loss: 0.04380374029278755\n","Loss: 0.04428895562887192\n","Loss: 0.05276874080300331\n","Loss: 0.040349431335926056\n","Epoch 18\n","Loss: 0.047777846455574036\n","Loss: 0.039784032851457596\n","Loss: 0.03525324910879135\n","Loss: 0.044758185744285583\n","Epoch 19\n","Loss: 0.041397903114557266\n","Loss: 0.0358206108212471\n","Loss: 0.04374789446592331\n","Loss: 0.04138211905956268\n","Epoch 20\n","Loss: 0.03760170564055443\n","Loss: 0.036157578229904175\n","Loss: 0.03270174562931061\n","Loss: 0.0290666650980711\n"]}]},{"cell_type":"code","source":["y_pred.data[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jBQ8Nq04EGM9","executionInfo":{"status":"ok","timestamp":1752385269106,"user_tz":-330,"elapsed":91,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}},"outputId":"980dabfe-655b-4405-efb9-7cfb15df9323"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.3926, -0.6818, -1.3391,  3.9107])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# eval loop\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","  for x_test, y_test in test_dataloader:\n","    y_pred = model(x_test)\n","    _, predicted = torch.max(y_pred.data, dim = 1)\n","    print(predicted)\n","    correct += (predicted == y_test).sum().item()\n","    total += y_test.size(0)\n","    print(f\"Accuracy: {correct/total}\")\n","\n","    print(f\"Loss: {loss.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jM7j7O3SB0X8","executionInfo":{"status":"ok","timestamp":1752385348642,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}},"outputId":"9d038991-c743-4c04-9cdf-12bc00e69796"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 0, 0, 0, 1, 1, 0, 3, 0, 2, 2, 1, 3, 1, 3, 2])\n","Accuracy: 0.75\n","Loss: 0.0290666650980711\n"]}]},{"cell_type":"code","source":["input_txt = input(\"Enter commit message: \")\n","input_emb = emb_model.encode([input_txt])\n","pred = model(torch.tensor(input_emb))\n","print(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcwgThZTEjbR","executionInfo":{"status":"ok","timestamp":1752385372709,"user_tz":-330,"elapsed":14012,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}},"outputId":"ea60e096-a72a-43e7-b217-53568b250780"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter commit message: just uploader readme.md file\n","tensor([[-1.8882,  0.4069,  0.2085,  1.2426]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["torch.max(pred.data, dim=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MkGjzYFyFVDE","executionInfo":{"status":"ok","timestamp":1752385683020,"user_tz":-330,"elapsed":42,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}},"outputId":"447f2315-2d9f-48e8-8ab6-b451903f77af"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.return_types.max(\n","values=tensor([1.2426]),\n","indices=tensor([3]))"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":[],"metadata":{"id":"Yq44AIO1FnMm","executionInfo":{"status":"aborted","timestamp":1752385269771,"user_tz":-330,"elapsed":18,"user":{"displayName":"Ramesh Vadgama","userId":"08118349214921079969"}}},"execution_count":null,"outputs":[]}]}